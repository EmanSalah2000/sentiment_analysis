{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmanSalah2000/sentiment_analysis/blob/main/reviews_sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6VMhU0lcTbb",
        "outputId": "2ebc678c-97bb-4fd5-8561-bf352f62f772"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh_Vy9wqcUwe",
        "outputId": "40321cec-b66e-42dd-912a-e4e4954bc9d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.5.18.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf9fH0EBCH57",
        "outputId": "e8646b4a-634b-4a7d-cf57-43a084f037a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "401 - Unauthorized\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d umbertogriffo/googles-trained-word2vec-model-in-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wc0vCPKHDP59",
        "outputId": "f5133e1b-950c-48b2-d790-d1ea4e3be6e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/googles-trained-word2vec-model-in-python.zip\n",
            "replace GoogleNews-vectors-negative300.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: ى\n",
            "error:  invalid response [ى]\n",
            "replace GoogleNews-vectors-negative300.bin? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace GoogleNews-vectors-negative300.bin.gz? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/googles-trained-word2vec-model-in-python.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWubOdEycdll",
        "outputId": "1a325be0-7b63-477f-90d2-4b01780056d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stop-words in /usr/local/lib/python3.7/dist-packages (2018.7.23)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim==4 in /usr/local/lib/python3.7/dist-packages (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==4) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4) (6.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install stop-words\n",
        "!pip install gensim==4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N0kn96OR8d6"
      },
      "source": [
        "# **1. Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsPx1emkcnHz",
        "outputId": "fa3b505f-a7b2-4904-c7ab-9bc52230413b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import linecache\n",
        "import nltk\n",
        "import random\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from stop_words import get_stop_words\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "import tensorflow as tf\n",
        "import tensorflow\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "stop_words = get_stop_words('english')\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRLMihJUSEOC"
      },
      "source": [
        "# **2. functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjmyDZRpcr4C"
      },
      "outputs": [],
      "source": [
        "def read_sentences(path):\n",
        "  myfile = open(path, 'r')\n",
        "  sentences = []\n",
        "  for i in range(len(myfile.readlines())):\n",
        "    x = linecache.getline(path, i).strip()\n",
        "    if x == \"<review_text>\":\n",
        "      line = i + 1\n",
        "      x = linecache.getline(path, line).strip()\n",
        "      while x != \"</review_text>\":\n",
        "        if len(x) >= 1:\n",
        "          sentences.append(x)\n",
        "        line += 1\n",
        "        x = linecache.getline(path, line).strip()\n",
        "      i = line\n",
        "  return sentences\n",
        "#####################################################################3\n",
        "def get_dataset():\n",
        "  path = \"/content/drive/MyDrive/sorted_data_acl\"\n",
        "  directories = os.listdir(path)\n",
        "  training_data, testing_data, training_labels, testing_labels = [], [], [], []\n",
        "  for dir in directories:\n",
        "    for filename in glob.glob(path + f\"/{dir}/*.review\"):\n",
        "      if dir == \"kitchen_&_housewares\":\n",
        "        sentences = read_sentences(filename)\n",
        "        for sentence in sentences:\n",
        "          testing_data.append(sentence)\n",
        "          testing_labels.append(filename.split(\"/\")[-1].replace(\".review\", \"\"))\n",
        "      else:\n",
        "        sentences = read_sentences(filename)\n",
        "        for sentence in sentences:\n",
        "          training_data.append(sentence)\n",
        "          training_labels.append(filename.split(\"/\")[-1].replace(\".review\", \"\"))\n",
        "  return training_data, testing_data, training_labels, testing_labels\n",
        "######################################################################################\n",
        "def preprocessing(sentence):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    for word in sentence.split(\" \"):\n",
        "      if word in stop_words:\n",
        "        sentence.replace(word, \"\")\n",
        "    sentence = re.sub(r\"[-–,.%')(&|!@#$^*?=_+<>\\d]\", '', sentence)\n",
        "    words = \"\"\n",
        "    for word in sentence.split():\n",
        "        word = lemmatizer.lemmatize(word)\n",
        "        words = words + word + \" \"\n",
        "    sentence = words\n",
        "    sentence = sentence.lower()\n",
        "    return sentence\n",
        "#######################################################################\n",
        "def get_embedings(model, data, labels):\n",
        "    w2v_embeddings_sentences = []\n",
        "    new_labels = []\n",
        "    for i in range(len(data)):\n",
        "      w2v_embeddings_sentence = []\n",
        "      for word in data[i].split(\" \"):\n",
        "        if word in list(model.index_to_key):\n",
        "          w2v_embeddings_word = model[word]\n",
        "          w2v_embeddings_sentence.append(w2v_embeddings_word)       \n",
        "      if len(w2v_embeddings_sentence) != 0:\n",
        "        w2v_embeddings_sentences.append(w2v_embeddings_sentence)\n",
        "        new_labels.append(labels[i])\n",
        "    return w2v_embeddings_sentences, new_labels\n",
        "#########################################################################\n",
        "def padding_zero(data_train,data_valid,data_test):\n",
        "  \n",
        "  max_num=0\n",
        "  for i in range(len(data_train)):\n",
        "    data_train[i]=np.array(data_train[i])\n",
        "    max_num=np.maximum(max_num,data_train[i].shape[0])\n",
        "  for i in range(len(data_valid)):\n",
        "    data_valid[i]=np.array(data_valid[i])\n",
        "    max_num=np.maximum(max_num,data_valid[i].shape[0])\n",
        "  for i in range(len(data_test)):\n",
        "    data_test[i]=np.array(data_test[i])\n",
        "    max_num=np.maximum(max_num,data_test[i].shape[0])\n",
        "\n",
        "  padded_data_train=np.zeros([len(data_train),max_num,data_train[0].shape[1]])\n",
        "  padded_data_valid=np.zeros([len(data_valid),max_num,data_valid[0].shape[1]])\n",
        "  padded_data_test=np.zeros([len(data_test),max_num,data_test[0].shape[1]])\n",
        "\n",
        "  for i in range(len(data_train)):\n",
        "    padded_data_train[i][:len(data_train[i])]=data_train[i]\n",
        "  for i in range(len(data_valid)):\n",
        "    padded_data_valid[i][:len(data_valid[i])]=data_valid[i]\n",
        "  for i in range(len(data_test)):\n",
        "    padded_data_test[i][:len(data_test[i])]=data_test[i]\n",
        "  return padded_data_train,padded_data_valid,padded_data_test,max_num\n",
        "###########################################################################\n",
        "def encoding_labels(label):\n",
        "  new_label=np.zeros([len(label),1])\n",
        "  for i in range(len(label)):\n",
        "    if(label[i]=='positive'):\n",
        "      new_label[i]=1\n",
        "    else:\n",
        "      new_label[i]=0\n",
        "  return new_label\n",
        "###############################################################################\n",
        "def bin_code(labels):\n",
        "  new_label=np.zeros([len(labels),1])\n",
        "  for i in range(len(labels)):\n",
        "    if(labels[i]>=0.5):\n",
        "      new_label[i]=1\n",
        "    else:\n",
        "      new_label[i]=0\n",
        "  return new_label\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5quag2XtSLBJ"
      },
      "source": [
        "# **3. load model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUZkeN34daox"
      },
      "outputs": [],
      "source": [
        "word2vec_pretrained = KeyedVectors.load_word2vec_format('/content/GoogleNews-vectors-negative300.bin', binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF5LdbRDSPh1"
      },
      "source": [
        "# **4. getting dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fLxrwhHdLbC"
      },
      "outputs": [],
      "source": [
        "training_data, testing_data, training_labels, testing_labels = get_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irDvsTpGSXOg"
      },
      "source": [
        "# **5. preprocessing data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYEkkeRsdMOp",
        "outputId": "d1c13a09-d440-43dd-c365-345b857d90a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147584\n",
            "147584\n",
            "32882\n",
            "32882\n",
            "147584\n",
            "147584\n",
            "32882\n",
            "32882\n"
          ]
        }
      ],
      "source": [
        "print(len(training_data))\n",
        "print(len(training_labels))\n",
        "print(len(testing_data))\n",
        "print(len(testing_labels))\n",
        "\n",
        "processed_training_data = []\n",
        "for sentence in training_data:\n",
        "  processed_training_data.append(preprocessing(sentence))\n",
        "\n",
        "processed_testing_data = []\n",
        "for sentence in testing_data:\n",
        "  processed_testing_data.append(preprocessing(sentence))\n",
        "\n",
        "  \n",
        "\n",
        "print(len(processed_training_data))\n",
        "print(len(training_labels))\n",
        "print(len(processed_testing_data))\n",
        "print(len(testing_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3m_eUJCSdf7"
      },
      "source": [
        "# **6.shuffle test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Ju4pbV-3IM"
      },
      "outputs": [],
      "source": [
        "# not run yet\n",
        "\n",
        "temp = list(zip(processed_testing_data, training_labels))\n",
        "random.shuffle(temp)\n",
        "processed_testing_data, training_labels = zip(*temp)\n",
        "processed_testing_data, training_labels = list(processed_testing_data), list(training_labels)\n",
        "\n",
        "\n",
        "\n",
        "# not run yet \n",
        "# processed_testing_data, training_labels = shuffle(np.array(processed_testing_data), np.array(training_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ToAfg3qSj9Y"
      },
      "source": [
        "# **7. split train valid  for training data and shuffle it**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80m0qcmcdWqR"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(processed_training_data[:1000], training_labels[:1000], test_size=0.33, random_state=42,shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5AXO-V6SutQ"
      },
      "source": [
        "# **8. getting embding for train valid test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qnMgTpXggqng"
      },
      "outputs": [],
      "source": [
        "training_embedings, training_embedings_labels = get_embedings(word2vec_pretrained, X_train, y_train)\n",
        "valid_embedings, valid_embedings_labels = get_embedings(word2vec_pretrained, X_valid, y_valid)\n",
        "test_embedings, test_embedings_labels = get_embedings(word2vec_pretrained, processed_testing_data[:300], testing_labels[:300])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuBO04JySuFk"
      },
      "source": [
        "# **9. padding zero for all the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-ITnrsbtgu3e"
      },
      "outputs": [],
      "source": [
        "pad_data_train,pad_data_valid,pad_data_test,max_number=padding_zero(training_embedings,valid_embedings,test_embedings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4WDsB19S7LM"
      },
      "source": [
        "# **10. reshape the train valid test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tQD3Alb1h26X"
      },
      "outputs": [],
      "source": [
        "pad_data_train=np.reshape(pad_data_train,(len(pad_data_train),pad_data_train.shape[1],pad_data_train.shape[2],1))\n",
        "pad_data_valid=np.reshape(pad_data_valid,(len(pad_data_valid),pad_data_valid.shape[1],pad_data_valid.shape[2],1))\n",
        "pad_data_test=np.reshape(pad_data_test,(len(pad_data_test),pad_data_test.shape[1],pad_data_test.shape[2],1))\n",
        "pad_data_train=np.array(pad_data_train)\n",
        "pad_data_valid=np.array(pad_data_valid)\n",
        "pad_data_test=np.array(pad_data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8i51SnnUjI05",
        "outputId": "d64333bf-a8c0-4997-9f9c-7071a75660dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(654, 297, 300, 1)\n",
            "(321, 297, 300, 1)\n",
            "(294, 297, 300, 1)\n"
          ]
        }
      ],
      "source": [
        "print(pad_data_train.shape)\n",
        "print(pad_data_valid.shape)\n",
        "print(pad_data_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoJq1v5wTHQs"
      },
      "source": [
        "# **11. encoding the labels and convert it to binary code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PIbnJzFHi8MN",
        "outputId": "4f5176ba-9a81-47bf-d09e-e1d25da1c9c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(654, 1)\n",
            "(321, 1)\n",
            "(294, 1)\n"
          ]
        }
      ],
      "source": [
        "y_train_update= encoding_labels(training_embedings_labels)\n",
        "y_valid_update=encoding_labels(valid_embedings_labels)\n",
        "y_test_update=encoding_labels(test_embedings_labels)\n",
        "\n",
        "y_train_update= bin_code(y_train_update)\n",
        "y_valid_update=bin_code(y_valid_update)\n",
        "y_test_update=bin_code(y_test_update)\n",
        "\n",
        "print(y_train_update.shape)\n",
        "print(y_valid_update.shape)\n",
        "print(y_test_update.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHI3m6JsTOeo"
      },
      "source": [
        "# **12. the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pdm8Z-f7jQuO",
        "outputId": "45656eb6-df78-40aa-9082-b7f238b337f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 295, 298, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 147, 149, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 145, 147, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 72, 73, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 70, 71, 64)        36928     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 318080)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                20357184  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,412,993\n",
            "Trainable params: 20,412,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='sigmoid', input_shape=(max_number,300,1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='sigmoid'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='sigmoid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.binary_crossentropy,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MygKP-7PTdgg"
      },
      "source": [
        "# **13. fitting the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vd5ueBZzjZYO",
        "outputId": "8ef5043a-4b74-4f08-cf14-1699132824ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "21/21 [==============================] - 103s 5s/step - loss: 0.3808 - accuracy: 0.9251 - val_loss: 0.3327 - val_accuracy: 0.9315\n",
            "Epoch 2/5\n",
            "21/21 [==============================] - 96s 5s/step - loss: 0.3464 - accuracy: 0.9251 - val_loss: 0.3006 - val_accuracy: 0.9315\n",
            "Epoch 3/5\n",
            "21/21 [==============================] - 96s 5s/step - loss: 0.3131 - accuracy: 0.9251 - val_loss: 0.2754 - val_accuracy: 0.9315\n",
            "Epoch 4/5\n",
            "21/21 [==============================] - 96s 5s/step - loss: 0.2883 - accuracy: 0.9251 - val_loss: 0.2587 - val_accuracy: 0.9315\n",
            "Epoch 5/5\n",
            "21/21 [==============================] - 96s 5s/step - loss: 0.2740 - accuracy: 0.9251 - val_loss: 0.2513 - val_accuracy: 0.9315\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff961877910>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(pad_data_train,y_train_update , epochs=5,validation_data=(pad_data_valid,y_valid_update),verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVHzAkmTlBv"
      },
      "source": [
        "# **14. predict the model for valdation and test**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0KZctYouplun"
      },
      "outputs": [],
      "source": [
        "y_pred_valid=model.predict(pad_data_valid)\n",
        "y_pred_valid=bin_code(y_pred_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6GR4p4DApcQq"
      },
      "outputs": [],
      "source": [
        "y_pred_test=model.predict(pad_data_test)\n",
        "y_pred_test=bin_code(y_pred_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LpgXoYVjliq6",
        "outputId": "24fd25ac-b83b-4160-f47e-6641b2317b9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(321, 1)\n",
            "(294, 1)\n",
            "(321, 1)\n",
            "(294, 1)\n"
          ]
        }
      ],
      "source": [
        "print(y_valid_update.shape)\n",
        "print(y_test_update.shape)\n",
        "\n",
        "print(y_pred_valid.shape)\n",
        "print(y_pred_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb1KKA2FTsmv"
      },
      "source": [
        "# **15. classification report for the valdation data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6t5FkxMwpaFe",
        "outputId": "b5fee39a-1741-4143-f9ac-b85b36fd3a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      1.00      0.96       299\n",
            "         1.0       0.00      0.00      0.00        22\n",
            "\n",
            "    accuracy                           0.93       321\n",
            "   macro avg       0.47      0.50      0.48       321\n",
            "weighted avg       0.87      0.93      0.90       321\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_valid_update, y_pred_valid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkY9v-awTz1b"
      },
      "source": [
        "# **16. classification report for test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QouFXqsCjgwf",
        "outputId": "277ec231-c774-486a-a0ef-4acafb77f3bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       294\n",
            "\n",
            "    accuracy                           1.00       294\n",
            "   macro avg       1.00      1.00      1.00       294\n",
            "weighted avg       1.00      1.00      1.00       294\n",
            "\n"
          ]
        }
      ],
      "source": [
        " print(classification_report(y_test_update, y_pred_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "reviews_sentiment_analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnV6A0DFvyql2ABvEOQ6Nk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}